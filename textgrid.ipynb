{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#-*- encoding: UTF-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tgt\n",
    "\n",
    "EXTENSION = 'TextGrid'\n",
    "\n",
    "def print_tiernames(filenames):\n",
    "\tfor filename in filenames:\n",
    "\t\ttry:\n",
    "\t\t\ttg = tgt.io.read_textgrid(filename)\n",
    "\t\t\tprint(filename)\n",
    "\t\t\tfor tiername in tg.get_tier_names():\n",
    "\t\t\t\tprint('\\t' + tiername)\n",
    "\t\texcept err:\n",
    "\t\t\tprint(filename + ' caused a problem.')\n",
    "\t\t\tsys.stderr.write('ERROR: %s\\n' % str(err))\n",
    "\n",
    "#def main():\n",
    "#    if argv is None:\n",
    "#        argv = sys.argv\n",
    "#    if len(argv) < 2:\n",
    "#        print('USAGE: ' + argv[0] + ' <list of TextGrid files or directories>')\n",
    "\n",
    "#\tlist_of_tg_files = []\n",
    "#\tfor arg in argv[1:]:\n",
    "#\t\tif os.path.exists(arg):\n",
    "#\t\t\tif os.path.isdir(arg):\n",
    "#\t\t\t\tlist_of_tg_files += [arg + '/' + filename for filename in os.listdir(arg) if filename.endswith(EXTENSION)]\n",
    "#\t\t\telse:\n",
    "#\t\t\t\tlist_of_tg_files.append(arg)\n",
    "#\t\telse:\n",
    "#\t\t\traise FileNotFoundException(arg)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    sys.exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txtgrid(filename):\n",
    "    tg = tgt.io.read_textgrid(filename)\n",
    "    return tg\n",
    "\n",
    "def add_text_tier(tg, NNM=\"\"):\n",
    "    new_tier = tgt.core.PointTier(name=NNM)\n",
    "    tg.add_tier(new_tier)\n",
    "    return new_tier\n",
    "\n",
    "def add_interval_tier(tg, NNM=\"\", STT=0, ETT=0):\n",
    "    new_tier = tgt.core.IntervalTier(name=NNM, start_time = STT, end_time = ETT)\n",
    "    tg.add_tier(new_tier)\n",
    "    return new_tier\n",
    "\n",
    "def print_tier(tg):\n",
    "    for tiername in tg.get_tier_names():\n",
    "        print('\\t' + tiername)   \n",
    "\n",
    "def write_txtgrid(tg, NNM):\n",
    "    tgt.io.write_to_file(tg, filename=NNM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'a03.textgrid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-081027de8072>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_txtgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a03.textgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mphonetier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tier_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'phone'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwordtier\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tier_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphonetier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0met\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphonetier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7a7039d1bb8c>\u001b[0m in \u001b[0;36mread_txtgrid\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_txtgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_textgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_text_tier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNNM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3-2019-07\\lib\\site-packages\\tgt\\io3.py\u001b[0m in \u001b[0;36mread_textgrid\u001b[1;34m(filename, encoding, include_empty_intervals)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtiers\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0malso\u001b[0m \u001b[0mincluded\u001b[0m \u001b[0mby\u001b[0m \u001b[0mspecifying\u001b[0m \u001b[0mtier\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0mtier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     or as a list.'''\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# Read whole file into memory ignoring empty lines and lines consisting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# solely of a single double quotes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'a03.textgrid'"
     ]
    }
   ],
   "source": [
    "tg = read_txtgrid('a03.textgrid')\n",
    "phonetier = tg.get_tier_by_name('phone')\n",
    "wordtier =  tg.get_tier_by_name('word')\n",
    "st = phonetier.start_time\n",
    "et = phonetier.end_time\n",
    "\n",
    "newtg = tgt.core.TextGrid(\"A0303.textgrid\")\n",
    "\n",
    "ctext = \"你昨天幾點回家啊\"\n",
    "ctier = add_text_tier(newtg, \"Chinese\")\n",
    "cann = tgt.core.Point((et-st)/2.0, ctext)\n",
    "ctier.add_annotation(cann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "tr = translator.translate(ctext, dest = 'en')\n",
    "print (tr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etier = add_text_tier(newtg, \"English\")\n",
    "eann = tgt.core.Point((et-st)/2.0,tr.text)\n",
    "etier.add_annotation(eann)\n",
    "\n",
    "# Two tiers from original textgrid file\n",
    "newtg.add_tier(wordtier)\n",
    "newtg.add_tier(phonetier)\n",
    "\n",
    "sy1tier = add_interval_tier(newtg, \"Syllabus\", st, et)\n",
    "to1tier = add_interval_tier(newtg, \"Tone\", st, et)\n",
    "\n",
    "newtg.add_tier(phonetier)\n",
    "\n",
    "sy2tier = add_interval_tier(newtg, \"Syllabus\", st, et)\n",
    "to2tier = add_interval_tier(newtg, \"Tone\", st, et)\n",
    "\n",
    "errtier = add_interval_tier(newtg, \"Error Type\", st, et)\n",
    "subtier = add_text_tier(newtg, \"Subject\")\n",
    "\n",
    "print_tier(newtg)\n",
    "write_txtgrid(newtg, \"A0303.textgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#-*- encoding: UTF-8 -*-\n",
    "\n",
    "## -------------------------\n",
    "## EHowNet API 2.0 Tutorial\n",
    "## -------------------------\n",
    "\n",
    "## 1. 載入 ehownet library 及 EHowNet ontology 資料庫\n",
    "\n",
    "# 在執行 python 之後，就可以直接 載入 ehownet library 了，\n",
    "# 然後，我們接著載入 EHowNet ontology。\n",
    "\n",
    "from ehownet_python3 import *\n",
    "tree=EHowNetTree(\"db/ehownet_ontology.sqlite\")\n",
    "#tree=EHowNetTree(\"db/ehownet_ontology_sim.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = [u'你', u'昨天', u'幾', u'點', u'回', u'家', u'啊']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你 : Nhaa \n",
      "昨天 : Ndabd \n",
      "幾 : Dbb Neu \n",
      "點 : Nfa Nfd Dfb VC2 VC2 VC2 VC2 Nab Nfg Nab \n",
      "回 : Nfa Nfa VC1 VD1 Nfi \n",
      "家 : Nfa !Ncb,Ncb \n",
      "啊 : I Tc \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 其中，ehownet_ontology.sqlite 是存放 EHowNet 的樹狀結構\n",
    "# 資料庫。這是一個 sqlite 資料庫檔案，有興趣可以使用 sqlite\n",
    "# 的應用程式 (如:SQLite Expert) 打開來看看。\n",
    "\n",
    "## 2. 查詢 EHowNet Ontology\n",
    "\n",
    "# 我們以「開心」一詞為例，呼叫 searchWord 函數。\n",
    "# 函數會傳回一組 ontology nodes。\n",
    "\n",
    "for sen in utterance:\n",
    "    list = tree.searchWord(sen)\n",
    "    p = False\n",
    "    for l in list:\n",
    "        if (not p) :\n",
    "            print(l.word, \":\", end = \" \")\n",
    "            p = True\n",
    "        print(l.pos_long, end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=tree.searchWord(u\"開心\")\n",
    "print(list)\n",
    "\n",
    "# 輸出結果：[word('開心.Nv,VH.1')]\n",
    "\n",
    "# 在這個例子中，因為「開心」只有一組語義，所以 list 中只包含\n",
    "# 一個 word node。\n",
    "\n",
    "# 另外，在 2.0 版中，我們可以發現，word 的表達式改為：\n",
    "#     word('開心.Nv,VH.1')\n",
    "# 這個表達式代表一個 sense，類似於 WordNet synset 的表達式。\n",
    "# 這個表達式在整個 ontology tree 中是唯一，所以我們也可以用\n",
    "# 表達式來取得資料：\n",
    "\n",
    "node=tree.word('開心.Nv,VH.1')\n",
    "print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. word 節點的資料結構\n",
    "\n",
    "# 一個 word 節點主要有下列的幾個欄位：\n",
    "\n",
    "# node.name    : 節點的名稱，在 word 類的節點中，就是表達式\n",
    "# node.word    : 詞彙本身\n",
    "# node.ehownet : EHowNet 定義式\n",
    "# node.pos     : 詞類\n",
    "# node.pos_long: 長詞類\n",
    "# node.meaning : word sense 的意義，也可以看做是英文翻譯。\n",
    "\n",
    "# 另外還有其他的一些欄位：\n",
    "# node.sid     : sense ID， sense 的流水號，對應到ckip 詞典\n",
    "#\t\t 的資料庫，沒有特別用處\n",
    "# node.node_type: 在 ontology 中的類別，可以分為 word 及 semanticType 兩類。\n",
    "# node.node_id  : 在 ontology 中的流水號，供 API 內部使用。\n",
    "# node.type    : \n",
    "#   在 ontology 中的類別可以再細分， semanticType 可分為 \n",
    "#\n",
    "#     primitive -- 該節點為「義原」\n",
    "#     category -- 該節點為「非義原」類別，在 EHowNet 中，是比較\n",
    "#                 細的分類節點\n",
    "#\n",
    "#   而 word 節點也可以再分為：\n",
    "#\n",
    "#     attachWord -- 語義和他的 semanticType 完全一致\n",
    "#     word -- 語義和他的 semanticType 不完全一致\n",
    "#\n",
    "#   這個區分在 EHowNet API 的使用上不是很重要的訊息。目前是使用在 \n",
    "#   EHowNet ontology online 中， attachWord 是直接附加在 semanticType \n",
    "#   的下的詞，例如在 ontology online 中我們可以看到 object|物件的節點，\n",
    "#   後面接了三個 words: \n",
    "#     object|物件 [ 事物, 客體, 對象 ]       \n",
    "#   這三個詞的定義式都是 {object|物件} ，和 semsnticType 一致，所以稱為\n",
    "#   attachWord。 其餘和 object|物件 不完全一致的詞，例如：\n",
    "#      一體 : {object|物體:qualification={complete|整}}\n",
    "#   不會直接放在中括號中的，類別就是 word\n",
    "\n",
    "print(node.name)\n",
    "print(node.word)\n",
    "print(node.ehownet)\n",
    "print(node.pos)\n",
    "print(node.pos_long)\n",
    "print(node.meaning)\n",
    "\n",
    "print(node.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. category 節點的資料結構\n",
    "\n",
    "# 一個 category 節點主要有下列的幾個欄位：\n",
    "\n",
    "# node.name    : 節點的名稱，也是 category 的唯一表達式\n",
    "# node.label   : EHowNet 定義式\n",
    "# node.type    : 詞類\n",
    "\n",
    "categoryList=node.getSemanticTypeList()\n",
    "category=categoryList[0]\n",
    "print(category)\n",
    "print(category.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. 上下位查詢\n",
    "\n",
    "# 上下位查詢的 API 提供在 ontology 中走訪的功能。基本的 API 如下：\n",
    "#\n",
    "# A. word node 的 member function:\n",
    "#    * word.getSemanticTypeList(): 取得詞彙的語義類\n",
    "#    * word.getSynonymWordList(): 取得詞彙的同義詞(定義式完全相同)\n",
    "#    * word.getSiblingWordList(): 取得同在 semanticType 下的近義詞\n",
    "#    * word.getDescendantWordList(): 取得在 semanticType 下及其下位的近義詞\n",
    "# 註： getSiblingWordList() 和 getDescendantWordList() 的差別在於前者所取得\n",
    "#      的近義詞限於同一層，後者則是將更深層的節點下的近義詞也取出。\n",
    "#      以「開心」為例，getSiblingWordList() 會取得 joyful|喜悅 下的詞，\n",
    "#      而 getDescendantWordList() 除了 「joyful|喜悅」 之外，還會取得 \n",
    "#      「狂喜|exultation」,「不快|be displeased」,「不悅|frown on」... 等\n",
    "#      下位節點下的詞。\n",
    "\n",
    "node=tree.word('開心.Nv,VH.1')\n",
    "print(node.getSemanticTypeList())\n",
    "print(node.getSynonymWordList())\n",
    "print(node.getSiblingWordList())\n",
    "print(node.getDescendantWordList())\n",
    "\n",
    "# B. category node 的 member function\n",
    "#    * category.getHypernym(): 取得上位義類\n",
    "#    * category.getHyponymList(): 取得下位義類\n",
    "#    * category.getWordList(): 取得附在義類下的詞彙\n",
    "#    * category.getAncestorList(): 取得所有上位義類，包含 TopNode\n",
    "#    * category.getDescendantList(): 取得所有下位義類\n",
    "#    * category.getDescendantWordList(): 取得節點內及所有下位義類節點內的\n",
    "#       近義詞\n",
    "# \n",
    "\n",
    "category=tree.semanticType('joyful|喜悅.1')\n",
    "print(category)\n",
    "\n",
    "parent=category.getHypernym()\n",
    "print(parent)\n",
    "\n",
    "ancestorList=category.getAncestorList()\n",
    "print(ancestorList)\n",
    "\n",
    "childList=parent.getHyponymList()\n",
    "print(childList)\n",
    "\n",
    "wordList=category.getWordList()\n",
    "print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. 檢查節點間的上下位關係:\n",
    "\n",
    "# categoryA.isHypernymOf(categoryB): category A 是否為 B 的上位\n",
    "# categoryA.isHyponymOf(categoryB): category A 是否為 B 的下位\n",
    "# categoryA.isAncestorOf(categoryB): category A 是否為 B 的祖先節點\n",
    "# categoryA.isDescendantOf(categoryB): category A 是否為 B 的子孫節點\n",
    "\n",
    "categoryA=tree.semanticType('joyful|喜悅.1')\n",
    "categoryB=tree.semanticType('FeelingByGood|好情.1')\n",
    "categoryC=tree.semanticType('thing|萬物.1')\n",
    "categoryD=tree.semanticType('event|事件.1')\n",
    "\n",
    "print(categoryA.isHyponymOf(categoryB))  # True\n",
    "print(categoryA.isHypernymOf(categoryB)) # False\n",
    "print(categoryB.isHyponymOf(categoryA))  # False\n",
    "print(categoryB.isHypernymOf(categoryA)) # True\n",
    "print(categoryD.isHypernymOf(categoryA)) # False\n",
    "print(categoryD.isAncestorOf(categoryA)) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. 節點的查詢功能\n",
    "#\n",
    "# tree.searchWord(word): 查詢 tree 中的詞彙\n",
    "# tree.searchSemanticType(semanticType): 查詢 tree 中的 semantic type\n",
    "# tree.word(word_name): 直接用 word 表達式取出節點\n",
    "# tree.semanticType(semantic_type_name): 直接用 semanticType 取出節點\n",
    "\n",
    "print(tree.searchWord(\"開心\"))\n",
    "print(tree.searchSemanticType(\"龍|dragon\"))\n",
    "print(tree.word('開心.Nv,VH.1'))\n",
    "print(tree.semanticType('龍|dragon.1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. 計算節點間的距離及路徑\n",
    "# tree.distance(node1, node2): 計算 node1 到 node2 的最短距離\n",
    "# tree.searchShortestPath(node1, node2): 計算 node1 到 node2 的短路徑\n",
    "\n",
    "categoryA=tree.semanticType('joyful|喜悅.1')\n",
    "categoryB=tree.semanticType('FeelingByGood|好情.1')\n",
    "categoryC=tree.semanticType('thing|萬物.1')\n",
    "categoryD=tree.semanticType('event|事件.1')\n",
    "wordE=tree.word('開心.Nv,VH.1')\n",
    "\n",
    "print(tree.distance(categoryA, categoryB))\n",
    "print(tree.distance(categoryD, wordE))\n",
    "print(tree.distance(\"大快人心\",\"不亦樂乎\"))\n",
    "print(tree.distance(tree.searchWord(\"大快人心\"),tree.searchWord(\"不亦樂乎\")))\n",
    "print(tree.distance(\"開心.Nv,VH.1\",\"joyful|喜悅.1\"))\n",
    "print(tree.distance(\"打\",tree.word(\"開心.Nv,VH.1\")))\n",
    "print(tree.distance(\"打\",\"開心.Nv,VH.1\"))\n",
    "\n",
    "print(tree.searchShortestPath(categoryD, categoryA))\n",
    "print(tree.searchShortestPath(\"打\",\"開心.Nv,VH.1\"))\n",
    "print(len(tree.searchShortestPath(\"打\",\"開心.Nv,VH.1\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
